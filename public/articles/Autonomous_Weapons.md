---
title: "The weapons were always autonomous"
date: "14/04/2025"
category: "Technology"
readingTime: 12
---

# The weapons were always autonomous

## Introduction

Autonomous weapons are a grim fixture of modern warfare, and disturbing footage from drones in the Ukraine war has pushed this awareness into the popular consciousness. 

It would be a mistake to see concern against autonomous weapons as purely contemporary, 
having been foreshadowed by films such as Terminator, weapons development during the second world war. 


You can take the human out of the war but you can't take the war out of the human, but that’s besides the point when you take the human out of the loop. 
The decision loop and man’s role within it is a common theme for this essay.

I'll first introduce Norbert Wiener, the prodigy who developed a weapons system we may refer to as cybernetic, a term he coined thereafter. 

Subsequently, I'll describe how the automata treatment became institutionalised in warfare, with the RAND Corporation at the centre.  

In the second part I'll widen my framing by deploying this rationalised understanding of war to understanding the evolution of tactics.  

### Contents
- Part 1: The cybernetic origins of autonomous control in WW2 and the Cold War 
- Part 2: Understanding the evolution of tactics in terms of feedback loops     
---

## Part 1: Cybernetic Genesis

### The Birth of Cybernetics  
World War 2 set forth an explosion of new weapons that changed the relation of man and machine.
Exemplary of this was Alan Turing who, famous for working on code breaking during WW2, developed the eponymous Turing test, framing what is now referred to as Artificial Intelligence.  

Not to understate the contributions of Turing, my departure point for this exploration is Norbert Wiener, who developed automatic gun targeting systems. 

Weiner, a child prodigy who earned his PhD at age 19 for his dissertation on mathematical logic, was an early researcher into stochastic and mathematical noise processes (random or probabilistic systems that evolve over time, such as signal interference or erratic movement, crucial for modelling uncertainty in real-world data and prediction)

Having done some work for the military at the end of World War One.  Under the direction of Warren Weaver Weiner, a well known mathematician at MIT, was brought into war work in 1941 on the problem of anti aircraft gunnery control. 

Weiner had worked closely with Vannevar Bush on an early analog computer, 
Bush had come to head up the Office of Scientific Research and Development (OSRD), having direct control over much of the science budget during WW2. 

The problem of gun control is this - how can one accurately aim anti-aircraft guns at fast-moving enemy bomber planes? Treating the plane and the pilot as a single entity, Weiner’s approached automatic gun control as a problem of prediction under uncertainty, 
he built a system that took in data, processed it and hence adjusted its aim to match the aircraft’s expected future position. 

This was a type of negative feedback system - it continuously compared the plane’s predicted trajectory to what actually happened, using the difference to correct itself, honing in on the target with each update.

Practically, this gun control mechanism had four key components: 
- A sensor, the then recently invented radar which provided real-time data on the target’s location
- A processor, an analog computer, taking in the input from the radar and then calculating a  prediction of the future position.
- An actuator: what physically positions the gun 
- A Human operator to oversee the operation. 

While it required human approval to fire weapons, it automated the tactical feedback loop. 
This metamorphosis from the human as executor to human as supervisor was significant for the ontology of war.

Weiner’s major conceptual leap had been to recognise that the system formed a closed-loop feedback circuit: data was continuously processed, and used to adjust behaviour in real time - and this feedback could be automated. 

It was the result of this insight that Weiner coined the field of cybernetics as ”the science of control and communications in the animal and machine”. 

In reality the operational impact of this gun control system was modest and  the practical extent of the gun’s autonomy and the human role as supervisor was little like what we could see now. It is similar in kind. The gun control experiment was a practical example that the machine could take over routine cognitive tasks like prediction and response. 

Weiner held deep reservations about the risk of removing humans from the decision making processes, fearing that over-delegating to machines could remove moral responsibility & critical judgement. 
He wanted to maintain man-in-the-loop control. Paul Scharre - who helped draft DoD policy on autonomy depicts the trajectory in three ways:  
- Human in the loop - direct human control 
- Human on the loop - human oversight over automated systems 
- Human out of the loop - full autonomy with no human intervention 

### RAND Corporation

RAND Corporation’s birth was a result of the formalisation of Operations Research during World War II.  In the 1950s RAND became the centre of System’s Analysis, 

Established in 1948, with the mandate: “a program of study and research on the broad subject of intercontinental warfare other than surface, with the objective of recommending to the Army Air Forces preferred techniques and instrumentalities for this purpose.”, the RAND Corporation became one of the home’s of cold war paranoia. 
 
RAND partially inspired Stanley Kubrick's dark comedy Doctor Strangelove or: How I learned to stop worrying and love the bomb, a film which showcased the absurdity of game theoretic approaches to war. The film portrays how,  in order to sustain the credible threat of retaliation against the United States in the event of nuclear war, the USSR creates a Doomsday device that cannot be turned off that will automatically respond to a first strike. An ironic crux of the film being how it cannot be turned off.   

The people working at RAND, a mixture of military theorists, mathematicians like von Neumann, and technocrats sought to create a new model of military rationality, one based not on heroism but on strategic logic, game theory, and theoretical models of decision-making under uncertainty.

This approach to war treated humans as functionally interchangeable components in a system, a conception of war which ontologically flattened man and machine by seeing them both in terms of feedback, communication and control. 

Seeing war as a command and control loop, lead to human decision-makers being increasingly treated like nodes in a network — agents with bounded rationality, whose behavior could be optimized, simulated, or replaced. 

This framing undergirded the shift towards seeing war as quantitative business, as Robert McNamara infamously did during the Vietnam War - trying to measure success in terms of linear metrics that diverged from the holistic reality. 

Whilst McNamara hasn’t been judged favourably by history, the integration of rationality into war through computers has only progressed.

The proto-genesis of autonomous weapons was in World War 2, during the Vietnam War Precision-Guided Munitions, such as Laser Guided Bombs were developed. This system radically improved targeting by…  
RAND Corporation’s war were wars of automata - war games became central to military planning 

Thomas Schelling, The Strategy of Conflict, is one of the most famous popularisers of the RAND school in his application of game theory to international strategy. 


## Recap

My intention with this section has been to suggest that the practical emergence of autonomous weapons began during World War Two, with Norbert Wiener’s automatic gun control project. His innovation - the closed circuit in which automatic feedback removed humans from the loop explicitly introduced the possibility of machines performing end-2-end tasks.

This, combined with the intellectual development of game theory, metamorphosed war into a rational system in which people - as predictable agents - were interchangeable with machines - a world in which the distinction between autonomous weapons and “subordinated” weapons is dissolved. 

The RAND Corporation, and the military industrial complex drove this trend, further institutionalising this new military epistemology.In section two, I argue that the logic of automation has always been embedded in military thought, modern, or at least post-world war two weapons merely represent an acceleration of existing tendencies.

---
## Part 2: Cybernetic Ontology

Now that we’ve developed the framework to understand the institutionalisation of autonomous weapons we can now think about how the drive towards rational war is central to the history of warfare as a whole.  

### Autonomous Tactics 
Tactical units are information processors, they follow a decision loop: they observe their environment, analyse the situation, decide the course of action and then execute on it. 

Tactical units are given instructions they have to execute - either through precise instructions that flow from the top or just a high-level goal (what is known as mission-type tactics) where the what is defined by command but the how is left to the unit’s discretion. 

The relationship between tactics and strategy has changed over time, as the increased complexity of the battlefield driven by novel weaponry has pushed decision-making downward - towards smaller tactical units. If all decision making was channelled through top-command in the modern battlefield the top would become overwhelmed. This decentralisation stepped up during the later stages of WW1 when the stalemate demanded a new approach. 

Highly centralised systems may be characterised by long feedback loops, single points of failure, and top-down command and control, while highly decentralised systems may be characterised by short feedback loops, multiple points of failure - or redundancy, and bottom-up decision making.
 
A story of this military machine can be told in terms of varying degrees of centralisation and decentralisation, characteristics of systems and the level of autonomy of the different components. 

### Autonomous Weapons 

Autonomous weapons take this farther - the unification of hardware with tactics - as the tactics are abstracted and embedded in the hardware. 

More generally, an autonomous weapon can be understood as a piece of hardware which displaces human judgement from the decision-making loop, as we saw with Norbert Wiener's automatic gun control system, or introduce feedback loops where none existed such as with the laser-guided bombs in the Vietnam War. Whilst these systems didn’t eliminate human involvement they redistributed agency. 

Autonomous weapons are only a part of the wider military machine - they still rely on a supply chain and are only deployed given a particular strategy. Autonomous weapons may even directly work together with humans. To speak of autonomous weapons as an essential type that exists is difficult. . 

From the perspective of command, autonomous weapons lie within the pattern of mission-type tactics that has become predominant.

Autonomous weapons remove command from the decision making loop - but is that fundamentally different to the platoons which have their local loop. From the perspective of command, an autonomous weapon is any entity that sets its own implementation. Autonomous weapons are only an epistemic novelty because of how they make explicit the implicit logic of decentralisation that has long existed in modern warfar.e 

Do autonomous weapons tend towards centralisation or decentralisation?


### Clockwork Armies: Automata not autonomy 
The Turk was a fake chess-playing automaton built in 1770 by Wolfgang von Kempelen, to those not in the know The Turk appeared to be a mechanical figure capable of playing - and often winning - complex games against human opponents. 

19th century sources claim that The Turk played, and defeated, Frederick the Great, the Monarch that transformed Prussia into a major European power, those claims are most likely apocryphal, it is true that as a hobby he loved to collect mechanical birds, and clockwork devices. 

These toys were a microcosm of Frederick’s approach to war, as he fashioned his armies after clockwork automata. 

Frederick’s armies were like clockwork, his soldiers were proto-automata, all individual initiative was proscribed. This was a maximally centralised army, all decision making flowed from the top to the soldiers. 

Military drills and the routinisation of the various tactical maneuvers, preceded Frederick Taylor’s Taylorism/Scientific Management, 

Frederick’s armies were organized into long, thin lines two or three ranks deep, soldiers in a given rank would fire & then reload as the next rank fired. This process was tightly choreographed resembling the logic of clockwork automata. 

Here there were automata, but not autonomy. Autonomy emerged when war became too complex for a single brain.   

### Auftragstaktik: Autonomy not automata

The pressure of the stalemate of World War Two forced adaptation, here the Germans invented the Stormtrooper, self-sufficient soldiers armed with novel weapons and new deep infiltration tactics. These Stormtrooper units had autonomy without the need to relay the information they received back to central command. 

This tactical development of mission-oriented tactics in which only the outlines of an operation are laid down, leaving the execution to field officers and soldiers reduced the accrual of friction up the chain of command, reducing strategic paralysis. 

The most well known integration of these new techniques and technologies of warfare was the Blitzkrieg. The blitzkrieg is is widely understood as the rapid advances into enemy territory enabled by advances in tanks and planes - but this technology was not the whole story. 

German tanks and planes, in contrast with their allied counterparts, were equipped with two-way communication capabilities. This allowed commanders and units on the ground to coordinate and respond dynamically to changing conditions without waiting for centralised orders. 

This technological advantage was wrapped up by the German military concept of Auftragstaktik - or mission-type tactics. This foreshadowed the types of distributed control that are obvious in the case of drone swarms.

This shift from purely vertical flows in communication shifted to lateral flows. 

Rather than saying how to execute a maneuver, units were provided with an objective and they were given the autonomy to achieve that objective.

This tactical doctrine had an OODA loop advantage, was more flexible under uncertainty / less brittle when plans were subverted by unexpected events. 

Part of German strategy was localisation of the decision making, an artifact we see in the modern organisation of soldiers. 



## Sources 

### Light summaries of my sources
- **[Pieces of the Action by Vannevar Bush](../books/Pieces_of_the_Action)**
- **[War in the Age of Intelligent Machines by Manuel De Landa](../books/War_in_the_Age_of_Intelligent_Machines)**
- **[Machine Dreams: Economics as a Cyborg Science by Phil Mirowski](../books/Machine_Dreams)**
- **[In Retrospect by Robert McNamara](../books/Retrospect)**
